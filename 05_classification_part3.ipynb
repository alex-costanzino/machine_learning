{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_classification_part3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyO0zOpISR6ageRaB23aUxl0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dMQ0aVZWDi1V"},"source":["# **Classification - Part III**"]},{"cell_type":"markdown","metadata":{"id":"nOF07ft5EnWg"},"source":["## Naive Bayes classifier\r\n","It's a statistics-based classifier (in particular on Bayes's theorem) that consider the contribution of all the attributes.\r\n","It assumes that each attribute is independent from the others: it's a very strong assumption (that's why it's called naive), almost never verified but nevertheless the method works.\r\n","\r\n","Probabilities are estimated with frequencies."]},{"cell_type":"markdown","metadata":{"id":"ckCkq_2CGfiJ"},"source":["### The Bayes's theorem\r\n","Given an hypotesis $H$ and an evidence $E$ that bears on that hypotesis, it holds: $$P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)}$$\r\n","The hypotesis is the class i.e. $c$, the evidence is the tuple of values of elements to be classified: $$P(c|E) = \\frac{P(E_1|H) \\cdot \\cdot \\cdot P(E_D|H) \\cdot P(H)}{P(E)}$$\r\n"]},{"cell_type":"markdown","metadata":{"id":"f5TRvmNeITOp"},"source":["### The Naive Bayes method\r\n","1. Compute the conditional probabilities from examples;\r\n","1. Apply the theorem.\r\n","\r\n","The denominator is the same for all the classes and it's eliminated by the normalization step.\r\n","\r\n","**Problem**: what happens if the value $v$ of the attribute $d$ never appears in the elements of class $c$? The probability of the class for that evidence drop to zero $P(d=v|c)=0$.\r\n","\r\n","Unfortunately this is quite common, especially in domains with many attributes and many distinct values."]},{"cell_type":"markdown","metadata":{"id":"E5-paxCmJWbI"},"source":["### Laplace smoothing\r\n","Letâ€™s start ignoring the details of the dataset, we consider only the value domains, and we know that for a given attribute $d$ there are $V_d$ distinct values.\r\n","Then a simple guess for the frequency of each distinct value of $d$ in\r\n","each class is $\\frac{1}{V_d}$.\r\n","\r\n","In this way we consider only the apriori probabilities.\r\n","We can smooth the computation of the aposteriori probabilities of values inside a class balancing it with the apriori probability.\r\n","\r\n","Let be:\r\n","* $\\alpha$ - Smoothing parameter (typically it's $1$, tradeoff between apriori and aposteriori information);\r\n","* $af_{d=v_i,c}$ - Absolute frequency of value $v_i$ in attribute $d$ over the class $c$;\r\n","* $af_{c}$ - Absolute frequency of class $c$ over the dataset;\r\n","* $V$ - Number of distinct values in attribute $d_i$ over the dataset.\r\n","\r\n","Then, the smoothed frequency will be: \r\n","$$sf_{d=d_i,c} = \\frac{af_{d=d_i,c}+\\alpha}{af_c + \\alpha V}$$\r\n","\r\n","With $\\alpha=0$ we obtain the standard case, with higher values we give more importance to the apriori probabilities. \r\n","When for some class the posterior probability of a value is zero, the apriori probability still gives an approximate guess."]},{"cell_type":"markdown","metadata":{"id":"v8Ezs5qyMICn"},"source":["### Missing values \r\n","Don't affect the model, no need to discard their istances: \r\n","* In the test istance the calculation of likelyhood simply omits the attribute, so it will be higher for all classe but compensated by the normalization;\r\n","* In the train istance the record is simply not included in the frequency counts for that attribute since the descriptive statistics are based on the number of values that occour, non on the number of istances (frequentistic approach)."]},{"cell_type":"markdown","metadata":{"id":"DmKqrvQRMwyk"},"source":["### Numeric values\r\n","The method based on frequencies is inapplicable, we need an additional assumption: the values have a gaussian distribution.\r\n","Instead of the fraction of counts we compute mean $\\mu$ and variance $\\sigma$ of the values, for each numeric attribute inside each class.\r\n","\r\n","Probability and probability density are closely related, but are not the\r\n","same thing:\r\n","* On a continuous domain, the probability of a variable assuming exactly a single real value is zero;\r\n","* A value of the density function is the probability that the variable lies in a small interval around that value.\r\n","\r\n","The value we use are, of course, rounded at some precision factor, if that precision factor is the same for all the classes, then we can disregard it.\r\n","If numeric values are missing, mean and standard deviation are based only on the values that are present.\r\n","\r\n","**Note**: there is a dramatic degradation when the simplicistic condition aren't met:\r\n","* Violation of **independence**: the weight of the feature is enforced;\r\n","* Violation of **gaussian distribution**: use the standard probability estimation for the appropriate distribution, if known, or uses estimation procedures (i.e. kernel density estimation)."]},{"cell_type":"markdown","metadata":{"id":"VWe4XoVbPhy5"},"source":["## Linear perceptron (artificial neuron)\r\n","Is a linear combination of weighted inputs.\r\n","For a dataset with numeric attributes learn a hyperplane such that all the positives lay on one side and all the negatives on the other.\r\n","\r\n","The hyperplane is described by a set of weights $w_0, \\dots, w_D$ in a linear equation on the data attributes $e_0, \\dots, e_D$.\r\n","The fictious attribute $e_0=1$ (bias term) is added to allow a hyperplan that does not pass through the origin. \r\n","\r\n","There are either none or infinite such hyperplanes:\r\n","$$w_0 \\cdot e_0 + w_1 \\cdot e_2 + \\dots + w_D \\cdot e_D > 0 \\to \\text{positive}$$\r\n","$$w_0 \\cdot e_0 + w_1 \\cdot e_2 + \\dots + w_D \\cdot e_D < 0 \\to \\text{negative}$$ \r\n","\r\n","![](https://i.ibb.co/grTpSGD/photo-2020-12-31-15-51-10.jpg)\r\n","\r\n","Each change of weight moves the hyperplane towards the missclassified istance.\r\n","For example, after the weight change for a positive istance:\r\n","$$(w_0 + e_0) \\cdot e_0 + (w_1 + e_1) \\cdot e_2 + \\dots + (w_D + e_D) \\cdot e_D = 0$$\r\n","The result of the equation is increased by a positive amount $e_0^2 + \\dots + e_D^2$, therefore the result will be less negative or possibly even positive.\r\n","\r\n","The corrections are incremental and can interfere with previous updates. \r\n","The algorithm converges if the dataset is linearly separable or if it's fixes an upper bound to the iterations."]},{"cell_type":"markdown","metadata":{"id":"-nPlzgHgU8lC"},"source":["## Support vector machines (SVM)\r\n","As we have seen before we have some limitations if datasets are not linearly separable. A solution could be to give up the linearity, but it's not feasible since the method would become intractable for any reasonable number of variables (large number of coefficients).\r\n","Moreover it would be extremely prone to overfitting.\r\n","\r\n","**Idea**: optimization of the hyperplane (with kernels maybe) rather than greedy search."]},{"cell_type":"markdown","metadata":{"id":"rLDi9ZrOWD7x"},"source":["### Maximum margin hyperplane\r\n","The linear perceptron accepts any hyperplane able to separate the classes of the training set.\r\n","Of course some hyperplanes are better than others for the classification of new items.\r\n","The **maximum margin hyperplane** gives the greatest separation between classes.\r\n","\r\n","![](https://i.ibb.co/dfC0SFk/Cattura.png)\r\n","\r\n","The *convex hull* of a set of points is the thightest enclosing convex polygon.\r\n","If the dataset is linearly separable the convex hulls of the classes do not intersect and the maximum hyperplane is as far as possible from both hulls.\r\n","\r\n","Only a subsets of point is sufficient to define the hulls: the **support vectors** (less expensive computationally).\r\n","\r\n","Finding the support vectors and the maximum margin hyperplane belongs to the well known class of *constrained quadratic optimization problems*:\r\n","$$\\max_{w_0,w_1,\\dots,w_D} M$$\r\n","$$\\sum_{j=1}^D w_j^2=1$$\r\n","$$c^e(w_0 + w_1x_1^e + \\dots + w_Dx_D^e)>M,\\forall e=1,\\dots,N$$\r\n","where the class $c^e$ of the example $i$ is either $+1$ or $-1$ and $M$ is the margin."]},{"cell_type":"markdown","metadata":{"id":"mDmT5coXWJlO"},"source":["### Soft margin vs Hard margin\r\n","It's quite common that the separating hyperplane does not exists (dataset non linear separable), in this case it's possible to:\r\n","* Find an hyperplane which almost separate the classes;\r\n","* Disregard examples which generates a very narrow margin.\r\n","\r\n","In any case we have:\r\n","* A greater robustness to individual observations;\r\n","* A better classification of most of the training observations.\r\n","\r\n","This is obtained by adding a constraint (hyperparmeter) to the optimization problem.\r\n","It's a regularization parameter called **penalty parameter of the error term** $C$ that controls the amount of overfitting."]},{"cell_type":"markdown","metadata":{"id":"9XFsu2P_YFuX"},"source":["### Non-linear class boundaries and the Kernel trick\r\n","The SVM method avoids the problem of overfitting and the non-linearity problem of boundaries can be overcome with a **non-linear mapping**: data are mapped in a new space (*feature space*), usually with higher dimensions, where an hyperplane exists.\r\n","![](https://miro.medium.com/max/872/1*zWzeMGyCc7KvGD9X8lwlnQ.png)\r\n","Once the hyperplane is obtained it's possible to going back to the original *input space*.\r\n","\r\n","The separating hyperplane computation requires a series of dot product computations among the training data vectors.\r\n","The mapping is defined on the basis of a particular familiy of functions called **kernel functions**, where the mapping doesn't need to be explicitly computed and so the computation is done in the input space.\r\n","This avoid an increase of the complexity.\r\n","\r\n","Kernel usually comes with some hyperparameters to tune.\r\n","*Rule of thumb*: start with a simpler kernel and then try more complex if necessary.\r\n","![](https://i.ibb.co/Q6qpsCN/Cattura.png)\r\n"]},{"cell_type":"markdown","metadata":{"id":"00hIN4IKa4_N"},"source":["### SVM complexity\r\n","The time complexity is mainly influenced by the efficiency of the optimization library.\r\n","The popular `libSVM` library scales from $\\mathcal{O}(DN^2)$ to $\\mathcal{O}(DN^3)$, depending on the effectivness of data catching in the library (in case of sparse data is reduced)."]},{"cell_type":"markdown","metadata":{"id":"q0tR96TIbeOt"},"source":["### SVM remarks\r\n","* Generally slower than simpler methods such as decision trees;\r\n","* Tuning is necessary;\r\n","* Very accurate results;\r\n","* Based on a theoretical model of learning;\r\n","* Not affected by local minima;\r\n","* Since no notion of distance is used, doesn't suffer the curse of dimensionality."]},{"cell_type":"markdown","metadata":{"id":"S1SNFteacGSu"},"source":["## Neural networks\r\n","It consists in many perceptron-like elements arranged in a hierarchical structure, inspired to the complex interconnections of neurons in animal brain.\r\n","\r\n","A neuron, the engine of reasoning, can be seen as a signal processor with a threshold.\r\n","The signal transimission from one neuron to another is weighted: the weights change over time, also due to learning.\r\n","\r\n","The signals transimitted are modelled as real numbers and the threshold is modeled as a mathematical function that has to be:\r\n","* Continuous;\r\n","* Differentiable;\r\n","* Limited;\r\n","\r\n","Possibly the derivative should be expressed in terms of the function itself for simplicity. \r\n","Usually they're non-linear to overcome the limit of linear decision boundaries and to reduce noise since linear functions completely tansfers the noise to the output.\r\n","The shape of the function influence the learning speed.\r\n","\r\n","Some examples: sigmoid function (*squashing function*), arctangent "]},{"cell_type":"markdown","metadata":{"id":"E-1sJjZVeXPU"},"source":["### Neural networks training\r\n","* Inputs feed an **input layer** (one input node for each dimension in the training set);\r\n","* Input layer feeds with weights a **hidden layer**;\r\n","* Hidden layer feed with weights an **output layer**.\r\n","\r\n","The number of nodes in the hidden layer is a parameter of the network, while the number of nodes in the output layer is related to number of different classes in the domain (we can use different encodings)\r\n","\r\n","*Example*:\r\n","\r\n","![](https://i.ibb.co/y5qJ0BV/photo-2021-01-01-11-27-37.jpg)\r\n","* The function $g(\\cdot)$ is the **transfer function** of the node;\r\n","* The unitary input $e_0$ is added for dealing with the bias as we did for the linear perceptron;\r\n","* Weights are for each edge connecting two nodes.\r\n","\r\n","**Feed-forward** defines which oriented edges are present:\r\n","* Edges connect only a node in a layer to a node in the following layer;\r\n","* Each node of one layer is connecred to all nodes of the following layer.\r\n","\r\n","In this way the signal flows from input to output without loops.\r\n","\r\n","![](https://i.ibb.co/6FpJB1Y/photo-2021-01-01-11-36-04.jpg)\r\n","Note: there are two loops since the changhes in weights change the behaviour of the network.\r\n","\r\n","In analogy with learning in the animal domain the examples must be repeatedly feed the network.\r\n","The weights encode the knowledge given by the supervised examples.\r\n","This encoding isn't easily understandable (*sub-symbolic approach*) and it's look like a structured set of real numbers.\r\n","\r\n","Convergence is **not** guaranteed.\r\n","\r\n","Important issues:\r\n","* Computing the weight corrections;\r\n","* Preparation of the training examples (standardization to have zero mean and unit variance);\r\n","* Termination conditon (when we are about to overfitting).\r\n"]},{"cell_type":"markdown","metadata":{"id":"jRZ1ob8Pi0PB"},"source":["### Error computation\r\n","Let be:\r\n","* $x$ the input vector;\r\n","* $y$ the desired output of a node;\r\n","* $w$ the input weight vectors of a node.\r\n","\r\n","Then: \r\n","$$E(w)=\\frac{1}{2}(y-\\text{Transfer}(w,x))^2$$\r\n","is the **quadratic error function**.\r\n","It should be convex since optima are easier (and fast) to find.\r\n","![](https://www.domsoria.com/wp-content/uploads/2020/03/convex_cost_function.jpg) "]},{"cell_type":"markdown","metadata":{"id":"iNyuUQHojuBp"},"source":["### Gradient computation\r\n","Objective: move towards a (local) minimum of the error function (gradient descent), following the gradient and computing the partial derivatives of the error as a function of the weights.\r\n","\r\n","The weight is changed subtracting the partial drivative multiplied by a **learning rate** constant (hyperparameter): it influences the convergence speed and represents a tradeoff between speed and precision.\r\n","$$w_{ij} = w_{ij} - \\lambda \\frac{\\partial E(w)}{\\partial w_{ij}}$$\r\n","The subtraction moves towards smaller errors (descent).\r\n","\r\n","![](https://i.ibb.co/NxVP2mF/photo-2021-01-01-11-52-32.jpg)"]},{"cell_type":"markdown","metadata":{"id":"7JkyHf3XlPKe"},"source":["### Learning modes\r\n","There are several methods for learning in neural networks:\r\n","* **Stochastic**: each forward propagation is immediately followed by a weight update. It introduces some noise in the gradient descent process since the gradient is computed by a single data point. It reduces the change of getting stucked in a local minimum. Good for online learning.\r\n","* **Batch**: many propagations occour before updating the weights, accumulating errors over the samples within a batch. Generally faster and stable descent since the updated is driven by the direction of the average error.\r\n","\r\n","As for all gradient tracking methods, local minima rather than global are usually found."]},{"cell_type":"markdown","metadata":{"id":"0eTRtPqNmEgj"},"source":["### Repetitions and stop criteria\r\n","A learning round over all the sample is called **epoch**.\r\n","Generally, after each epoch the network classification capability will be improved.\r\n","Several epochs will be necessary and after each epoch the starting weights will be different.\r\n","\r\n","The learning rate can be changed in different epochs:\r\n","* In the beginning a higher learning rate can push faster towards the desired direction;\r\n","* In later epochs a lower learning rate can push more precisely towards a minum.\r\n","\r\n","The learning process can stop when:\r\n","* Weight updates are small;\r\n","* Classification error rate goes below the chosen targer;\r\n","* A timeout or memoryout condition is reached."]},{"cell_type":"markdown","metadata":{"id":"toPuvnYYw0t1"},"source":["### Regularization\r\n","Overfitting is possible if the network is too complex respect to the complexity of the problem.\r\n","\r\n","Some regularization techniques can be used to improve the generalization capacity of the model, usually modifying the performance (error) function.\r\n","In essence, the improvement of performance is obtained by reducing the loss function in order to smooth the fitting data (the amount of regularization has to be tuned)."]},{"cell_type":"markdown","metadata":{"id":"Sl7pG4KWx33T"},"source":["## Istance learning"]},{"cell_type":"markdown","metadata":{"id":"TQBCu1B0x9ua"},"source":["### $K$-nearest neighbours classifer\r\n","The method consists in:\r\n","* Keeping all the training data (the model is the entire dataset);\r\n","* The predictions are made by computing the similarity between the new sample and each training instance;\r\n","* Picks the $K$ entries in the database which are closest to the new data point and do a majority vote.\r\n","\r\n","*Parameters* number of neighbours to check and the metric used to compute the distances (Mahalanobis distance has usually good performances)."]}]}
